{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "4e6cefb0049d48a2f4648d752841bb06",
     "grade": false,
     "grade_id": "cell-b038e38b5e3072a9",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# IST 718: Big Data Analytics\n",
    "\n",
    "- Professor: Daniel Acuna <deacuna@syr.edu>\n",
    "- TAs: Tong Zeng <tozeng@syr.edu>, Priya Matnani <psmatnan@syr.edu>\n",
    "\n",
    "## General instructions:\n",
    "\n",
    "- You are welcome to discuss the problems with your classmates but __you are not allowed to copy any part of your answers either from your classmates or from the internet__\n",
    "- You can put the homework files anywhere you want in your http://notebook.acuna.io workspace but _do not change_ the file names. The TAs and the professor use these names to grade your homework.\n",
    "- Remove or comment out code that contains `raise NotImplementedError`. This is mainly to make the `assert` statement fail if nothing is submitted.\n",
    "- The tests shown in some cells (i.e., `assert` and `np.testing.` statements) are used to grade your answers. **However, the professor and TAs will use __additional__ test for your answer. Think about cases where your code should run even if it passess all the tests you see.**\n",
    "- Before downloading and submitting your work through Blackboard, remember to save and press `Validate` (or go to \n",
    "`Kernel`$\\rightarrow$`Restart and Run All`). \n",
    "- Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load these packages\n",
    "from pyspark.ml import feature\n",
    "from pyspark.ml import clustering\n",
    "from pyspark.ml import Pipeline, PipelineModel\n",
    "from pyspark.sql import functions as fn\n",
    "import numpy as np\n",
    "from pyspark.sql import SparkSession, types\n",
    "from pyspark.ml import feature, regression, evaluation, Pipeline\n",
    "from pyspark.sql import functions as fn, Row\n",
    "import matplotlib.pyplot as plt\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2. Clustering and Latent Dirichlet Allocation\n",
    "\n",
    "I would recommend to follow the notebook `unsupervised_learning.ipynb` first, shared through the IST 718 repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following dataset contains information about the diet of European contries around 1970"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "9102f93b73342f27ff5eb15d025c29c1",
     "grade": false,
     "grade_id": "cell-8898c04579b9221e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "protein_df = spark.read.csv('proteindata.txt', sep='\\t', inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1: (10 pts)\n",
    "\n",
    "Performed a PCA transformation on the `protein_df` dataframe, using all features. Use two principal components. The pipeline transformation should have a standard scaler step where you only center the data before you pass it onto the PCA transformation. Store the pipeline transformation in `pipe_pca`. The transformation should produce a column named `pc` which has the two principal components requested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "cb982914cbab5d8d552cafcab8a6f41b",
     "grade": false,
     "grade_id": "cell-18ebd4f77c37a8e3",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# (10 pts) Create ds_programs_text_df here\n",
    "pipe_pca = Pipeline(stages=[\n",
    "    feature.VectorAssembler(inputCols=[\"RedMeat\", \"WhiteMeat\", \"Eggs\", \"Milk\", \"Fish\", \"Cereals\", \"Starch\", \"Nuts\", \"FruitVeg\"],\n",
    "                           outputCol='features'),\n",
    "    feature.StandardScaler(withMean=True, withStd = False,\n",
    "                           inputCol='features', outputCol='centered_features'\n",
    "                          ),\n",
    "    feature.PCA(k=2, inputCol='centered_features', outputCol='pc')\n",
    "]).fit(protein_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the schema of how the transformation should look like:\n",
    "\n",
    "```python\n",
    "pipe_pca.transform(protein_df).printSchema()\n",
    "```\n",
    "\n",
    "```console\n",
    "root\n",
    " |-- Country: string (nullable = true)\n",
    " |-- RedMeat: double (nullable = true)\n",
    " |-- WhiteMeat: double (nullable = true)\n",
    " |-- Eggs: double (nullable = true)\n",
    " |-- Milk: double (nullable = true)\n",
    " |-- Fish: double (nullable = true)\n",
    " |-- Cereals: double (nullable = true)\n",
    " |-- Starch: double (nullable = true)\n",
    " |-- Nuts: double (nullable = true)\n",
    " |-- FruitVeg: double (nullable = true)\n",
    " |-- features: vector (nullable = true)\n",
    " |-- centered_features: vector (nullable = true)\n",
    " |-- pc: vector (nullable = true)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "45e0f0dc7c75b0c288bbd0f818803065",
     "grade": true,
     "grade_id": "cell-20fb7c865c3ddf0e",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# (10 pts)\n",
    "np.testing.assert_equal(pipe_pca.transform(protein_df).count(), 25)\n",
    "np.testing.assert_equal(type(pipe_pca), PipelineModel)\n",
    "np.testing.assert_equal(len(pipe_pca.transform(protein_df).first().pc), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2 (10 pts)\n",
    "\n",
    "Extract the absolute loadings from the PCA transformation in the pipeline and the appropriate feature names from the vector assembler. For each principal component, extract the top feature---the biggest absoluate loadings. Comment on what principal component 1 vs principal component 2 mean based on these top features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "59aa36c0b782325c43cd3225a6363e6e",
     "grade": true,
     "grade_id": "cell-ccff5d0a482e4302",
     "locked": false,
     "points": 10,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>load_pc1</th>\n",
       "      <th>load_pc2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RedMeat</td>\n",
       "      <td>-0.150654</td>\n",
       "      <td>0.132695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WhiteMeat</td>\n",
       "      <td>-0.129489</td>\n",
       "      <td>0.0434349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Eggs</td>\n",
       "      <td>-0.0672709</td>\n",
       "      <td>0.020946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Milk</td>\n",
       "      <td>-0.425376</td>\n",
       "      <td>0.830856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fish</td>\n",
       "      <td>-0.126976</td>\n",
       "      <td>-0.292307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Cereals</td>\n",
       "      <td>0.860865</td>\n",
       "      <td>0.406169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Starch</td>\n",
       "      <td>-0.0668512</td>\n",
       "      <td>-0.0760486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Nuts</td>\n",
       "      <td>0.113909</td>\n",
       "      <td>-0.0700662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>FruitVeg</td>\n",
       "      <td>0.0202353</td>\n",
       "      <td>-0.169221</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        word   load_pc1   load_pc2\n",
       "0    RedMeat  -0.150654   0.132695\n",
       "1  WhiteMeat  -0.129489  0.0434349\n",
       "2       Eggs -0.0672709   0.020946\n",
       "3       Milk  -0.425376   0.830856\n",
       "4       Fish  -0.126976  -0.292307\n",
       "5    Cereals   0.860865   0.406169\n",
       "6     Starch -0.0668512 -0.0760486\n",
       "7       Nuts   0.113909 -0.0700662\n",
       "8   FruitVeg  0.0202353  -0.169221"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "principal_components = pipe_pca.stages[-1].pc.toArray()\n",
    "#principal_components\n",
    "vocabulary = list([\"RedMeat\", \"WhiteMeat\", \"Eggs\", \"Milk\", \"Fish\", \"Cereals\", \"Starch\", \"Nuts\", \"FruitVeg\"])\n",
    "pc1 = list(principal_components[:,0])\n",
    "pc2 = list(principal_components[:,1])\n",
    "pc_loadings = pd.DataFrame([vocabulary, pc1, pc2]).T.rename(columns={0: 'word', \n",
    "                                                                          1: 'load_pc1',2: 'load_pc2'})\n",
    "#pc_loadings\n",
    "pc_loadings.apply({'word': lambda x: x, 'load_pc1': np.abs}, axis=0).\\\n",
    "sort_values(by='load_pc1', ascending=False).head(5)\n",
    "#The biggest absolute loading in pc1 is Cereals (followed by Milk) with 0.86 which means that Cereal explains the most variability in the\n",
    "#first principal loading \n",
    "\n",
    "pc_loadings.apply({'word': lambda x: x, 'load_pc2': np.abs}, axis=0).\\\n",
    "sort_values(by='load_pc2', ascending=False).head(1)\n",
    "#The biggest absolute loading in pc1 is Milk (followed by Cereal) with 0.83 which means that Milk explains the most variability in the\n",
    "#second principal loading \n",
    "\n",
    "pc_loadings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3 (10 pts)\n",
    "\n",
    "Use the following `exploded_df` dataframe to explore which countries are at the extreme the principal component 1. In particular, create a dataframe `smallest_pc1_df` which contains the columns `country`, `pc_1`, and `pc_2` of the country with the smallest `pc_1`. Similarly, create `largest_pc1_df` with the largest `pc_1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "1ef2748ac9694e621534f919c4698390",
     "grade": false,
     "grade_id": "cell-ef40fee5c7d7bf9a",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "@fn.udf(returnType=types.FloatType())\n",
    "def vector_select(vector_col, element):\n",
    "    return float(vector_col[element])\n",
    "\n",
    "exploded_df = pipe_pca.transform(protein_df).select('country', \n",
    "                                      vector_select('pc', fn.lit(0)).alias('pc_1'),\n",
    "                                      vector_select('pc', fn.lit(1)).alias('pc_2'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should contain something similar to this:\n",
    "\n",
    "```\n",
    "exploded_df.show()\n",
    "```\n",
    "\n",
    "```\n",
    "+---------+-----------+------------+\n",
    "|  country|       pc_1|        pc_2|\n",
    "+---------+-----------+------------+\n",
    "|  Albania|  14.102253|  -1.3218285|\n",
    "|  Austria| -5.4612746|   1.5477921|\n",
    "|  Belgium| -6.0766153|  -1.4793622|\n",
    "| Bulgaria|  26.115946|   3.3188622|\n",
    "|Czechosl.|   3.317268|  -2.0923328|\n",
    "|  Denmark|-13.8607855|   1.3738568|\n",
    "| EGermany| -4.9024506|    -8.35954|\n",
    "|  Finland| -12.262294|   11.290117|\n",
    "|   France|  -6.345336|  0.67163473|\n",
    "|   Greece|   9.036383|   3.0326154|\n",
    "|  Hungary|  10.804568|  -2.3634377|\n",
    "|  Ireland| -11.857348|    5.312214|\n",
    "|    Italy|   6.308735|  -1.3141143|\n",
    "| Netherl.| -11.808532|    2.132773|\n",
    "|   Norway| -11.005402|-0.077100314|\n",
    "|   Poland|  2.5261996|   2.9990442|\n",
    "| Portugal| 0.78424096|  -16.753153|\n",
    "|  Romania|  19.067295|   2.5912552|\n",
    "|    Spain|  1.9230922|  -10.482929|\n",
    "|   Sweden|-14.8419485|   0.7262486|\n",
    "+---------+-----------+------------+\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "96d4b13f36029a10d80b2727f2a66dbe",
     "grade": false,
     "grade_id": "cell-e3414da54a6ab4f5",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+---------+\n",
      "| country|     pc_1|     pc_2|\n",
      "+--------+---------+---------+\n",
      "|Bulgaria|26.115946|3.3188622|\n",
      "+--------+---------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "smallest_pc1_df = exploded_df.orderBy(fn.abs(exploded_df.pc_1)).limit(1)\n",
    "largest_pc1_df = exploded_df.orderBy(fn.abs(exploded_df.pc_1), ascending = False).limit(1)\n",
    "largest_pc1_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6045a3a99e15219280c28400bd802e7c",
     "grade": true,
     "grade_id": "cell-11ee0e6c6a5219e2",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# (10 pts)\n",
    "np.testing.assert_equal(smallest_pc1_df.count(), 1)\n",
    "np.testing.assert_equal(largest_pc1_df.count(), 1)\n",
    "np.testing.assert_array_less(smallest_pc1_df.first().pc_1, largest_pc1_df.first().pc_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4 (10 pts)\n",
    "\n",
    "In this question, you will find three clusters of the raw features (without any modification) of `protein_df` using K-means. Do this using a pipeline transformation called `pipe_cluster` which should produce a prediction column called `prediction`. **To reproduce your results, use default parameters of Kmeans and set the `seed` parameter to 0**\n",
    "\n",
    "Produce a dataframe `protein_clustered_df` with the `pipe_cluster` transformation applied to `protein_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "1065593910d638d2c98e2d554eaaabeb",
     "grade": false,
     "grade_id": "cell-2b84d6996a843772",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "pipe_cluster = Pipeline(stages=[\n",
    "    feature.VectorAssembler(inputCols=[\"RedMeat\", \"WhiteMeat\", \"Eggs\", \"Milk\", \"Fish\", \"Cereals\", \"Starch\", \"Nuts\", \"FruitVeg\"],\n",
    "                           outputCol='features'),\n",
    "    clustering.KMeans(k=3, featuresCol='features', predictionCol='prediction', seed=0)\n",
    "]).fit(protein_df)\n",
    "\n",
    "protein_clustered_df = pipe_cluster.transform(protein_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "dfb9762f17b64f2d9ce5ed591937cc22",
     "grade": true,
     "grade_id": "cell-d352a2be7c9d703f",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# 10 pts\n",
    "np.testing.assert_equal(type(pipe_cluster), PipelineModel)\n",
    "np.testing.assert_equal(len(pipe_cluster.stages), 2)\n",
    "np.testing.assert_equal(protein_clustered_df.count(), 25)\n",
    "assert 'prediction' in protein_clustered_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5 (10 pts)\n",
    "\n",
    "According to Wikipedia, the Mediterranean diet includes \"proportionally high consumption of olive oil, legumes, unrefined cereals, fruits, and vegetables, moderate to high consumption of fish, moderate consumption of dairy products (mostly as cheese and yogurt), moderate wine consumption, and low consumption of non-fish meat products.\" https://en.wikipedia.org/wiki/Mediterranean_diet\n",
    "\n",
    "We have some of these countries in our protein dataset: Italy, Spain, Portugal, and Greece.\n",
    "\n",
    "With code and code comments, test the hypothesis that these countries all belong to the same cluster using the clustering you did in question 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can use the following list in your code\n",
    "mediterranean_countries = ['Italy', 'Spain', 'Portugal', 'Greece']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "415e2f135d2fffb38e3a4f04cb8b4c36",
     "grade": true,
     "grade_id": "cell-9285cef3ce344449",
     "locked": false,
     "points": 10,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+---------+----+----+----+-------+------+----+--------+--------------------+----------+\n",
      "| Country|RedMeat|WhiteMeat|Eggs|Milk|Fish|Cereals|Starch|Nuts|FruitVeg|            features|prediction|\n",
      "+--------+-------+---------+----+----+----+-------+------+----+--------+--------------------+----------+\n",
      "|  Greece|   10.2|      3.0| 2.8|17.6| 5.9|   41.7|   2.2| 7.8|     6.5|[10.2,3.0,2.8,17....|         1|\n",
      "|   Italy|    9.0|      5.1| 2.9|13.7| 3.4|   36.8|   2.1| 4.3|     6.7|[9.0,5.1,2.9,13.7...|         2|\n",
      "|Portugal|    6.2|      3.7| 1.1| 4.9|14.2|   27.0|   5.9| 4.7|     7.9|[6.2,3.7,1.1,4.9,...|         2|\n",
      "|   Spain|    7.1|      3.4| 3.1| 8.6| 7.0|   29.2|   5.7| 5.9|     7.2|[7.1,3.4,3.1,8.6,...|         2|\n",
      "+--------+-------+---------+----+----+----+-------+------+----+--------+--------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "protein_clustered_df.where(protein_clustered_df.Country.isin(mediterranean_countries)).show()\n",
    "#Italy, Portugal and Spain belong to the same cluster, but Greece belongs to a different cluster. \n",
    "#The amount of RedMeat, Milk, Cereal and Nuts consumed in Greece is higher than those in the other Mediterranean countries, \n",
    "#this makes it belong to a different cluster\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
